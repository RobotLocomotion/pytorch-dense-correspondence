{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "\n",
    "# key_dynam\n",
    "from key_dynam.utils.utils import get_project_root, load_yaml\n",
    "from key_dynam.dataset.drake_sim_episode_reader import DrakeSimEpisodeReader\n",
    "from key_dynam.utils import transform_utils\n",
    "from key_dynam.utils import drake_image_utils\n",
    "\n",
    "# pdc\n",
    "from dense_correspondence.dataset.dynamic_drake_sim_dataset import DynamicDrakeSimDataset\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import reproject_pixels\n",
    "from dense_correspondence.correspondence_tools import correspondence_plotter\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import compute_correspondence_data, pad_correspondence_data\n",
    "from dense_correspondence_manipulation.utils.utils import getDenseCorrespondenceSourceDir, set_cuda_visible_devices\n",
    "import dense_correspondence.loss_functions.utils as loss_utils\n",
    "import dense_correspondence_manipulation.utils.utils as pdc_utils\n",
    "import dense_correspondence_manipulation.utils.visualization as vis_utils\n",
    "\n",
    "GPU_LIST = [1]\n",
    "set_cuda_visible_devices(GPU_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"2019-11-26-00-03-48-223155\"\n",
    "DATASET_NAME = \"top_down_same_view\"\n",
    "DATASET_NAME = \"top_down_rotated\"\n",
    "\n",
    "dataset_root = os.path.join(get_project_root(), \"data/dev/experiments/05/data\", DATASET_NAME)\n",
    "\n",
    "multi_episode_dict = DrakeSimEpisodeReader.load_dataset(dataset_root)\n",
    "# make pdc dataset now\n",
    "\n",
    "# placeholder for now\n",
    "config_file = os.path.join(getDenseCorrespondenceSourceDir(), \n",
    "                           'config/dense_correspondence/global/drake_sim_dynamic.yaml')\n",
    "config = load_yaml(config_file)\n",
    "dataset = DynamicDrakeSimDataset(config, multi_episode_dict, phase=\"train\")\n",
    "dataset_valid = DynamicDrakeSimDataset(config, multi_episode_dict, phase=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_name = list(multi_episode_dict.keys())[0]\n",
    "print(\"episode name:\", episode_name)\n",
    "\n",
    "idx = 0\n",
    "episode = multi_episode_dict[episode_name]\n",
    "print(\"episode._non_image_data.keys()\", episode._non_image_data.keys())\n",
    "\n",
    "camera_names = list(episode.camera_names)\n",
    "camera_name_a = camera_names[0]\n",
    "camera_name_b = camera_names[1]\n",
    "\n",
    "# camera_name_a = \"camera_1_top_down\"\n",
    "# camera_name_b = \"camera_2_top_down_rotated\"\n",
    "data_a = episode.get_image_data(camera_name_a, idx)\n",
    "data_b = episode.get_image_data(camera_name_b, idx)\n",
    "\n",
    "print(\"data_a.keys()\", data_a.keys())\n",
    "\n",
    "# plot RGB\n",
    "plt.figure()\n",
    "plt.imshow(data_a['rgb'])\n",
    "plt.title('rgb_a')\n",
    "\n",
    "# plot RGB b\n",
    "plt.figure()\n",
    "plt.imshow(data_b['rgb'])\n",
    "plt.title('rgb_b')\n",
    "\n",
    "# depth\n",
    "depth_float32 = data_a['depth_float32']\n",
    "depth_float32 = np.clip(depth_float32, 0, 2)\n",
    "plt.figure()\n",
    "plt.imshow(depth_float32)\n",
    "plt.title(\"depth\")\n",
    "\n",
    "# label\n",
    "label = data_a['label']\n",
    "label_cp = np.copy(label)\n",
    "print(\"label.dtype\", label.dtype)\n",
    "color_label = drake_image_utils.colorize_labels(label_cp)\n",
    "plt.figure()\n",
    "plt.imshow(color_label)\n",
    "plt.title('label')\n",
    "plt.show()\n",
    "\n",
    "# mask\n",
    "mask = data_a['mask']\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "plt.title('mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "\n",
    "# model_name = \"2019-12-03-21-25-46-128603_top_down_same_view\"\n",
    "# model_name = \"2019-12-03-22-51-17-805212_top_down_rotated\"\n",
    "# model_name = \"2019-12-03-23-40-30-486661_top_down_rotated_sigma_5\"\n",
    "model_name = \"2019-12-04-01-32-12-010393_top_down_rotated_sigma_5\"\n",
    "network_folder = os.path.join(get_project_root(), \"data/dev/experiments/05/trained_models\", model_name)\n",
    "\n",
    "epoch = 155\n",
    "model_file = os.path.join(network_folder, \"net_dy_epoch_%d_iter_0_model.pth\" %(epoch))\n",
    "model = torch.load(model_file)\n",
    "model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize learned heatmap for single image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdc_utils.reset_random_seed()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "print(\"device:\")\n",
    "idx = 0\n",
    "\n",
    "MODEL_ENABLED = True\n",
    "# DATA_TYPE = \"train\"\n",
    "DATA_TYPE = \"valid\"\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # indices\n",
    "    b = 0\n",
    "    n = 10\n",
    "\n",
    "    data = None\n",
    "    if DATA_TYPE == \"train\":\n",
    "        data = dataset._getitem(episode, \n",
    "                                idx,\n",
    "                                camera_name_a=camera_name_a, \n",
    "                                camera_name_b=camera_name_b)\n",
    "    elif DATA_TYPE == \"valid\":\n",
    "        data = dataset_valid._getitem(episode, \n",
    "                                idx,\n",
    "                                camera_name_a=camera_name_a, \n",
    "                                camera_name_b=camera_name_b)\n",
    "        \n",
    "    \n",
    "    \n",
    "    data_a = data['data_a']\n",
    "    rgb_tensor_a = data_a['rgb_tensor'].to(device).unsqueeze(0)\n",
    "    rgb_tensor_b = data['data_b']['rgb_tensor'].to(device).unsqueeze(0)\n",
    "    rgb_a = data_a['rgb']\n",
    "    uv_a = data['matches']['uv_a'].unsqueeze(0).to(device) # [B, 2, N]\n",
    "    uv_b = data['matches']['uv_b'].unsqueeze(0).to(device) # [B, 2, N]\n",
    "    valid = data['matches']['valid'].unsqueeze(0).to(device) # [B, N]\n",
    "#     uv_a = uv_a[:,]\n",
    "\n",
    "    # [1,D,H,W]\n",
    "    if MODEL_ENABLED:\n",
    "        out_a = model.forward(rgb_tensor_a)\n",
    "        des_img_a = out_a['descriptor_image']\n",
    "        \n",
    "        out_b = model.forward(rgb_tensor_b)\n",
    "        des_img_b = out_b['descriptor_image']\n",
    "\n",
    "    # uv\n",
    "    uv = uv_b[b, :, n]\n",
    "    uv_gt = uv\n",
    "    u = uv[0]\n",
    "    v = uv[1]\n",
    "    rgb_w_reticle = np.copy(data['data_b']['rgb'])\n",
    "    label_color = [0, 255, 0]\n",
    "    vis_utils.draw_reticle(rgb_w_reticle, u, v, label_color)\n",
    "\n",
    "    sz = 2\n",
    "    figsize = (6.4*sz, 4.8*sz)\n",
    "#     plt.figure(figsize=figsize)\n",
    "#     plt.imshow(rgb)\n",
    "#     plt.title(\"rgb w/ reticle\")\n",
    "\n",
    "    sigma = 1\n",
    "    heatmap_type = \"exp\"\n",
    "\n",
    "    if MODEL_ENABLED:\n",
    "        # des_a\n",
    "        # [B,N,D]\n",
    "        des_a = pdc_utils.index_into_batch_image_tensor(des_img_a, uv_a).permute([0,2,1])\n",
    "\n",
    "        # get heatmap and plot it\n",
    "        heatmap_pred = loss_utils.compute_heatmap_from_descriptors(des_a,\n",
    "                                                               des_img_b,\n",
    "                                                               sigma=sigma,\n",
    "                                                               type=heatmap_type)\n",
    "        \n",
    "        # compute best match\n",
    "        B = rgb_tensor_a.shape[0]\n",
    "        D = rgb_tensor_a.shape[1]\n",
    "        H = rgb_tensor_a.shape[2]\n",
    "        W = rgb_tensor_a.shape[3]\n",
    "        N = uv_a.shape[2]\n",
    "\n",
    "        # [B, N, D, H, W]\n",
    "        expand_batch_des_a = pdc_utils.expand_descriptor_batch(des_a, H, W)\n",
    "        expand_des_img_b = pdc_utils.expand_image_batch(des_img_b, N)\n",
    "\n",
    "        # [B, N, H, W]\n",
    "        norm_diff = (expand_batch_des_a - expand_des_img_b).norm(p=2, dim=2)\n",
    "\n",
    "        best_match_dict = pdc_utils.find_pixelwise_extreme(norm_diff, type=\"min\")\n",
    "        \n",
    "        # [B, N, 2]\n",
    "        best_match_indices = best_match_dict['indices']\n",
    "        uv_best_match = best_match_indices[b, n, :]\n",
    "        pixel_diff = (uv_best_match - uv_gt).type(torch.float)\n",
    "        \n",
    "        print(\"pixel_error\", torch.norm(pixel_diff))\n",
    "        \n",
    "        # draw\n",
    "        label_color = [255, 0, 0]\n",
    "        vis_utils.draw_reticle(rgb_w_reticle, uv_best_match[0], uv_best_match[1], label_color)\n",
    "        print(\"best_match_indices.shape\", best_match_indices.shape)\n",
    "        \n",
    "        \n",
    "        # [B, N, 2]\n",
    "        uv_b_pred = best_match_dict['indices']\n",
    "        uv_b_gt = uv_b.permute([0, 2, 1])\n",
    "        pixel_diff = (uv_b_pred - uv_b_gt).type(torch.float)\n",
    "\n",
    "        # [B, N]\n",
    "        pixel_error = torch.norm(pixel_diff, dim=2)\n",
    "\n",
    "        # [M, 2]\n",
    "        pixel_error_valid = pdc_utils.extract_valid(pixel_error, valid)\n",
    "\n",
    "        avg_pixel_error = torch.mean(pixel_error_valid)\n",
    "        median_pixel_error = torch.median(pixel_error_valid)\n",
    "        \n",
    "        print(\"avg_pixel_error\", avg_pixel_error)\n",
    "        print(\"median_pixel_error\", median_pixel_error)\n",
    "        \n",
    "# do the drawing        \n",
    "\n",
    "heatmap_pred_np = heatmap_pred.cpu().numpy()[b, n]\n",
    "print(heatmap_pred_np.shape)\n",
    "print(\"np.max(heatmap_pred)\", np.max(heatmap_pred_np))\n",
    "print(\"np.min(heatmap_pred)\", np.min(heatmap_pred_np))\n",
    "\n",
    "# plt.figure(figsize=figsize)\n",
    "# plt.imshow(heatmap_pred_np)\n",
    "# plt.title(\"heatmap\")\n",
    "\n",
    "# get colormap\n",
    "colormap = vis_utils.colormap_from_heatmap(heatmap_pred_np, normalize=True)\n",
    "# plt.figure(figsize=figsize)\n",
    "# plt.imshow(colormap)\n",
    "# plt.title(\"colormap\")\n",
    "\n",
    "colormap_PIL = Image.fromarray(colormap, mode='RGB')\n",
    "rgb_PIL = Image.fromarray(rgb_w_reticle, mode='RGB')\n",
    "\n",
    "alpha = 0.3\n",
    "blend = Image.blend(rgb_PIL, colormap_PIL, alpha)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(blend)\n",
    "plt.title(\"blend\")\n",
    "\n",
    "rgb_a = np.copy(data['data_a']['rgb'])\n",
    "vis_utils.draw_reticle(rgb_a, uv_a[b, 0, n], uv_a[b, 1, n], label_color=[0, 255, 0])\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(rgb_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize descriptors over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdc_utils.reset_random_seed()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "print(\"device:\")\n",
    "idx = 0\n",
    "idx_step = 5\n",
    "\n",
    "MODEL_ENABLED = True\n",
    "DATA_TYPE = \"valid\"\n",
    "\n",
    "sz = 2\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "figsize = (6.4*sz*num_cols, 4.8*sz*num_rows)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # indices\n",
    "    b = 0\n",
    "    n = 10\n",
    "\n",
    "    data = None\n",
    "    dataset_tmp = None\n",
    "    if DATA_TYPE == \"train\":\n",
    "        dataset_tmp = dataset\n",
    "    elif DATA_TYPE == \"valid\":\n",
    "        dataset_tmp = dataset_valid\n",
    "        \n",
    "    \n",
    "    data = dataset_tmp._getitem(episode, \n",
    "                                idx,\n",
    "                                camera_name_a=camera_name_a, \n",
    "                                camera_name_b=camera_name_b)\n",
    "    \n",
    "    data_a = data['data_a']\n",
    "    rgb_tensor_a = data_a['rgb_tensor'].to(device).unsqueeze(0)\n",
    "    rgb_tensor_b = data['data_b']['rgb_tensor'].to(device).unsqueeze(0)\n",
    "    rgb_a = data_a['rgb']\n",
    "    uv_a = data['matches']['uv_a'].unsqueeze(0).to(device) # [B, 2, N]\n",
    "    uv_b = data['matches']['uv_b'].unsqueeze(0).to(device) # [B, 2, N]\n",
    "    valid = data['matches']['valid'].unsqueeze(0).to(device) # [B, N]\n",
    "\n",
    "    # [1,D,H,W]\n",
    "    out_a = model.forward(rgb_tensor_a)\n",
    "    des_img_a = out_a['descriptor_image']\n",
    "\n",
    "    # [B,N,D]\n",
    "    des_a = pdc_utils.index_into_batch_image_tensor(des_img_a, uv_a).permute([0,2,1])\n",
    "    des_a_ref = des_a[b,n,:].unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # [1,1,D]\n",
    "    uv_a_ref = uv_a.permute([0,2,1])[b,n,:].unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    print(\"uv_a_ref.shape\", uv_a_ref.shape)\n",
    "\n",
    "\n",
    "    episode.length    \n",
    "    for i in range(100):\n",
    "        idx_cur = i*idx_step\n",
    "        \n",
    "        if idx_cur >= episode.length:\n",
    "            break\n",
    "        \n",
    "        data = dataset_tmp._getitem(episode, \n",
    "                                idx_cur,\n",
    "                                camera_name_a=camera_name_a, \n",
    "                                camera_name_b=camera_name_b)\n",
    "        \n",
    "        rgb = data['data_a']['rgb']\n",
    "        rgb_tensor = data['data_a']['rgb_tensor'].unsqueeze(0).to(device)\n",
    "        out = model.forward(rgb_tensor)\n",
    "        des_img = out['descriptor_image']\n",
    "        \n",
    "\n",
    "        # compute best match\n",
    "        _, D, H, W = rgb_tensor.shape\n",
    "        \n",
    "        # note B = 1, N = 1\n",
    "        B, N, _ = uv_a_ref.shape\n",
    "\n",
    "        # [B, N, D, H, W]\n",
    "        expand_batch_des_a = pdc_utils.expand_descriptor_batch(des_a_ref, H, W)\n",
    "        expand_des_img_b = pdc_utils.expand_image_batch(des_img, N)\n",
    "\n",
    "        # [B, N, H, W]\n",
    "        norm_diff = (expand_batch_des_a - expand_des_img_b).norm(p=2, dim=2)\n",
    "\n",
    "        best_match_dict = pdc_utils.find_pixelwise_extreme(norm_diff, type=\"min\")\n",
    "\n",
    "        # [B, N, 2]\n",
    "        best_match_indices = best_match_dict['indices']\n",
    "        # uv_best_match should have same shape as uv_a_ref\n",
    "        uv_best_match = best_match_indices[0, 0, :]\n",
    "\n",
    "        # draw reference image\n",
    "        label_color = [0, 255, 0]\n",
    "        rgb_a_wr = np.copy(rgb_a)\n",
    "        vis_utils.draw_reticle(rgb_a_wr, uv_a_ref[0,0,0], uv_a_ref[0,0,1], label_color)\n",
    "        \n",
    "        # draw target image\n",
    "        label_color = [255,0,0]\n",
    "        rgb_wr = np.copy(rgb)\n",
    "        vis_utils.draw_reticle(rgb_wr, uv_best_match[0], uv_best_match[1], label_color)\n",
    "        \n",
    "        figname = \"target idx: %d\" %(idx_cur)\n",
    "        fig = plt.figure(figname, figsize=figsize)\n",
    "        axes = fig.subplots(num_rows, num_cols, squeeze=False)\n",
    "        axes[0,0].imshow(rgb_a_wr)\n",
    "        axes[0,1].imshow(rgb_wr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
