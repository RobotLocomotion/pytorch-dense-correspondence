{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of finding correspondences\n",
    "\n",
    "- Demos generating correspondences in numpy only\n",
    "- Demos same in pytorch\n",
    "- Simple timing experiments in pytorch\n",
    "- Demos generating non-correspondences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a pixel correspondence -- first in numpy only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys; sys.path.append('../test'); sys.path.append('../dataset')\n",
    "import numpy_correspondence_finder\n",
    "import correspondence_plotter\n",
    "from labelfusion import LabelFusionDataset\n",
    "\n",
    "# from LabelFusion dataset: labelfusion.csail.mit.edu\n",
    "lf = LabelFusionDataset()\n",
    "scene = \"2017-06-13-20\"\n",
    "log_dir = lf.get_full_path_for_scene(scene)\n",
    "img_a_index = \"0000000020\"\n",
    "img_b_index = \"0000000400\"\n",
    "\n",
    "uv_a = (300,200)\n",
    "uv_a, uv_b = numpy_correspondence_finder.find_pixel_correspondence(log_dir, img_a_index, img_b_index, uv_a=uv_a)\n",
    "correspondence_plotter.plot_correspondences_from_dir(log_dir, img_a_index, img_b_index, uv_a, uv_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a pixel correspondence -- now in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import correspondence_finder\n",
    "import time\n",
    "uv_a = (300,200)\n",
    "\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose, \n",
    "                                                                    uv_a=uv_a)\n",
    "print time.time() - start\n",
    "if uv_a is not None:\n",
    "    correspondence_plotter.plot_correspondences_from_dir(log_dir, img_a_index, img_b_index, uv_a, uv_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch implementation -- finding many correspondences\n",
    "\n",
    "Note that in this example, about 1/10 get pruned due to either:\n",
    "\n",
    "1. No depth measurement in image a\n",
    "2. Reprojection is outside FOV of image b\n",
    "3. Occluded: the point from image a is occluded in image b\n",
    "4. No depth measurement in image b (so can't be sure if occluded or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "num_attempts = 50\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose, \n",
    "                                                                    num_attempts=num_attempts)\n",
    "print time.time() - start, \"seconds\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])\n",
    "if uv_a is not None:\n",
    "    correspondence_plotter.plot_correspondences_from_dir(log_dir, img_a_index, img_b_index, uv_a, uv_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On CPU, how fast can we do many, many samples? (10x samples, let's not plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attempts = 50000\n",
    "\n",
    "img_a_index_2 = \"0000000002\"\n",
    "img_b_index_2 = \"0000000300\"\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index_2)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index_2)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='CPU')\n",
    "print time.time() - start, \"seconds 1st time\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='CPU')\n",
    "print time.time() - start, \"seconds 2nd time\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])\n",
    "\n",
    "img_a_index_3 = \"0000000020\"\n",
    "img_b_index_3 = \"0000000500\"\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index_3)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index_3)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='CPU')\n",
    "print time.time() - start, \"seconds on a new image pair\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GPU, how fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attempts = 50000\n",
    "\n",
    "img_a_index_4 = \"0000000003\"\n",
    "img_b_index_4 = \"0000000301\"\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index_4)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index_4)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='GPU')\n",
    "print time.time() - start, \"seconds 1st time\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='GPU')\n",
    "print time.time() - start, \"seconds 2nd time\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])\n",
    "\n",
    "img_a_index_5 = \"0000000021\"\n",
    "img_b_index_5 = \"0000000501\"\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index_5)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index_5)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='GPU')\n",
    "print time.time() - start, \"seconds on a new image pair\"\n",
    "print \"num attempted: \", num_attempts\n",
    "print \"num valid:     \", len(uv_a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Conclusions\n",
    "\n",
    "It's a little subtle -- cold start switching to the GPU is slow on the first image (takes a couple seconds). But on the second time on that image, the matching is quite fast, just slightly faster than the CPU (~0.018 vs 0.023 seconds).  You might think this is only because it's the same image, but no -- loading in a different image still doesn't see the 2-second cold start. (Perhaps there is pre-fetching?  Would be interested to look into it more in future.) \n",
    "\n",
    "Big picture though, this margin is not that large, and so without looking in deeper, computation time might be dominated by something agnostic to whether ths reprojection runs on CPU or GPU (for example, image io).\n",
    "\n",
    "And an additional benefit is that by keeping on CPU, we will not need to take any additional precious GPU memory during training, allowing batch sizes to be higher for training.  (This process of generating correspondences happens during training, generated with each randomly selected pairs of same-scene RGBD images in the training set.)\n",
    "\n",
    "So all in all, I am guessing this step of my pipeline will stay on CPU.  But the peace of mind is priceless knowing how fast it _could_ have been on the GPU!\n",
    "\n",
    "\n",
    "### Note:\n",
    "\n",
    "- CPU: 10-core i7-6950x\n",
    "- GPU: GTX 1080 Ti\n",
    "- For reference, with other simple benchmarks on this system (matrix multiply), I see up to [5,800x speedup on the GPU](https://github.com/peteflorence/matrix-multiply/blob/master/MatrixMultiply.ipynb) (at least, not accounting for initialization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attempts = 3\n",
    "\n",
    "img_a_index_2 = \"0000000001\"\n",
    "img_b_index_2 = \"0000001000\"\n",
    "img_a_rgb, img_a_depth, img_a_pose = lf.get_specific_rgbd_with_pose(scene, img_a_index_2)\n",
    "img_b_rgb, img_b_depth, img_b_pose = lf.get_specific_rgbd_with_pose(scene, img_b_index_2)\n",
    "\n",
    "start = time.time()\n",
    "uv_a, uv_b = correspondence_finder.batch_find_pixel_correspondences(img_a_depth, img_a_pose, \n",
    "                                                                    img_b_depth, img_b_pose,\n",
    "                                                                    num_attempts=num_attempts,\n",
    "                                                                    device='CPU')\n",
    "print time.time() - start, \"seconds for matches\"\n",
    "print \"num attempted: \", num_attempts\n",
    "if uv_a is not None:\n",
    "    print \"num valid:     \", len(uv_a[0])\n",
    "\n",
    "start = time.time()\n",
    "uv_b_non_matches = correspondence_finder.create_non_correspondences(uv_b,num_non_matches_per_match=50)\n",
    "print  time.time() - start, \"seconds for non-matches\"\n",
    "if uv_b_non_matches is not None:\n",
    "    print uv_b_non_matches[0].shape\n",
    "\n",
    "    import torch\n",
    "    # This just checks to make sure nothing is out of bounds\n",
    "    print torch.min(uv_b_non_matches[0])\n",
    "    print torch.min(uv_b_non_matches[1])\n",
    "    print torch.max(uv_b_non_matches[0])\n",
    "    print torch.max(uv_b_non_matches[1])\n",
    "    \n",
    "    fig, axes = correspondence_plotter.plot_correspondences_from_dir(log_dir, img_a_index_2, img_b_index_2, uv_a, uv_b, show=False)\n",
    "    uv_a_long = (torch.t(uv_a[0].repeat(3, 1)).contiguous().view(-1,1), torch.t(uv_a[1].repeat(3, 1)).contiguous().view(-1,1))\n",
    "    uv_b_non_matches_long = (uv_b_non_matches[0].view(-1,1), uv_b_non_matches[1].view(-1,1) )\n",
    "    correspondence_plotter.plot_correspondences_from_dir(log_dir, img_a_index_2, img_b_index_2,\n",
    "                                                  uv_a_long, uv_b_non_matches_long,\n",
    "                                                  use_previous_plot=(fig,axes),\n",
    "                                                  circ_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note for future:\n",
    "\n",
    "In the plot above (at least at time of this writing), you can see a potential issue that would want a little bit of a refactor.\n",
    "\n",
    "It is currently possible for \"non-matches\" to sample parts of image b for which there is no known depth.\n",
    "\n",
    "This could be an issue for example, if it just so happens that that corner of image b matches image a.\n",
    "\n",
    "Two things though:\n",
    "\n",
    "1. Once I have depths from the actual projection against world model, this will be less of an issue, since there will be less holes.\n",
    "2. That combined with that issue hopefully being rare, means maybe I shouldn't worry about it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
