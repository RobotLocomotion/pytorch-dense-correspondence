{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "\n",
    "# key_dynam\n",
    "from key_dynam.utils.utils import get_project_root, get_data_root\n",
    "\n",
    "\n",
    "# pdc\n",
    "from dense_correspondence.dataset.dynamic_drake_sim_dataset import DynamicDrakeSimDataset\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import reproject_pixels\n",
    "from dense_correspondence.correspondence_tools import correspondence_plotter\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import compute_correspondence_data, pad_correspondence_data\n",
    "from dense_correspondence_manipulation.utils.utils import getDenseCorrespondenceSourceDir, getDictFromYamlFilename, get_data_dir\n",
    "import dense_correspondence.loss_functions.utils as loss_utils\n",
    "from dense_correspondence.dataset.spartan_episode_reader import SpartanEpisodeReader\n",
    "from dense_correspondence_manipulation.utils.constants import DEPTH_IM_SCALE\n",
    "import dense_correspondence_manipulation.utils.utils as pdc_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that this only works for static scenes/episodes, not dynamic ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    return load_spartan_data()\n",
    "\n",
    "\n",
    "def load_spartan_data():\n",
    "    #### SPARTAN ########\n",
    "    \n",
    "    # caterpillar\n",
    "#     dataset_processed_dir = os.path.join(get_data_root(), 'dev/pdc/2018-04-16-14-25-19/processed')\n",
    "    dataset_processed_dir = \"/home/manuelli/data_ssd/pdc/logs_proto/2018-04-16-14-25-19/processed\"\n",
    "    \n",
    "    \n",
    "    # caterpillar\n",
    "    episode_name = \"2018-04-16-14-25-19\"\n",
    "    \n",
    "#     # shoe\n",
    "#     episode_name = \"2018-05-14-22-57-40\"\n",
    "#     dataset_processed_dir = os.path.join(get_data_dir(), \"logs_proto\", episode_name, 'processed')\n",
    "\n",
    "    config_file = os.path.join(getDenseCorrespondenceSourceDir(), 'config/dense_correspondence/global/integral_heatmap_3d.yaml')\n",
    "    config = getDictFromYamlFilename(config_file)\n",
    "    \n",
    "    episode = SpartanEpisodeReader(config, dataset_processed_dir)\n",
    "    episode_name = \"episode_0\"\n",
    "    multi_episode_dict = {episode_name: episode}\n",
    "    return multi_episode_dict, config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# episode, config = load_data()\n",
    "multi_episode_dict, config = load_data()\n",
    "episode_name = list(multi_episode_dict.keys())[0]\n",
    "episode = multi_episode_dict[episode_name]\n",
    "indices = episode.indices\n",
    "\n",
    "\n",
    "sz = 2\n",
    "figsize = (6.4*sz, 4.8*sz)\n",
    "\n",
    "\n",
    "# episode_name = \"episode_0\"\n",
    "# multi_episode_dict = {episode_name: episode}\n",
    "# print(\"multi_episode_dict.keys()\", multi_episode_dict.keys())\n",
    "\n",
    "\n",
    "dataset = DynamicDrakeSimDataset(config, multi_episode_dict)\n",
    "\n",
    "\n",
    "idx_a = indices[0]\n",
    "idx_b = indices[20]\n",
    "# idx_a = 0\n",
    "# idx_b = 20\n",
    "episode = multi_episode_dict[episode_name]\n",
    "\n",
    "camera_names = list(episode.camera_names)\n",
    "camera_name_a = camera_names[0]\n",
    "camera_name_b = camera_names[0]\n",
    "\n",
    "data_a = episode.get_image_data(camera_name_a, idx_a)\n",
    "data_b = episode.get_image_data(camera_name_b, idx_b)\n",
    "\n",
    "print(\"data_a.keys()\", data_a.keys())\n",
    "\n",
    "# plot RGB\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(data_a['rgb'])\n",
    "plt.title('rgb_a')\n",
    "\n",
    "\n",
    "# mask\n",
    "mask = data_a['mask']\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "plt.title('mask')\n",
    "\n",
    "depth = data_a['depth_int16']\n",
    "print(depth.dtype)\n",
    "print(\"max(depth)\", np.max(depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Visualize pointcloud with meshcat\n",
    "Disable if you don't want to test this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "if False:\n",
    "    \n",
    "    # meshcat\n",
    "    import meshcat\n",
    "    import meshcat.geometry as g\n",
    "    import meshcat.transformations as tf\n",
    "    \n",
    "    from dense_correspondence_manipulation.utils import meshcat_utils\n",
    "    from dense_correspondence_manipulation.utils import utils as pdc_utils\n",
    "    from dense_correspondence_manipulation.utils import torch_utils\n",
    "    from dense_correspondence_manipulation.utils.constants import DEPTH_IM_SCALE\n",
    "    from dense_correspondence_manipulation.utils.visualization import draw_reticles\n",
    "\n",
    "    K = data_a['K']\n",
    "    depth = data_a['depth_int16'] / DEPTH_IM_SCALE\n",
    "    rgb = data_a['rgb']\n",
    "    out = pdc_utils.project_image_to_pointcloud(depth, K, rgb)\n",
    "\n",
    "    vis = meshcat.Visualizer(zmq_url=\"tcp://127.0.0.1:6000\")\n",
    "    vis.delete()\n",
    "    geom = g.Points(\n",
    "        g.PointsGeometry(out['pts'].transpose(), color=out['color'].transpose()/255.0),\n",
    "        g.PointsMaterial(size=0.001)\n",
    "    )\n",
    "    vis['pointcloud'].set_object(geom)\n",
    "\n",
    "    # set the transform\n",
    "    T_W_C = data_a['T_world_camera']\n",
    "    # T_inv = np.linalg.inv(T_W_C)\n",
    "    vis['pointcloud'].set_transform(T_W_C)\n",
    "\n",
    "\n",
    "    \n",
    "    ###### TEST pytorch unprojection method #############\n",
    "    \n",
    "    # test the pytorch unprojection method\n",
    "    K_inv_np = np.linalg.inv(K)\n",
    "    \n",
    "    # [B, 3, 3]\n",
    "    K_inv = torch.from_numpy(K_inv_np).unsqueeze(0)\n",
    "    \n",
    "    # [B, N, 2]\n",
    "    mask = torch.Tensor(data_a['mask'])\n",
    "    uv = torch_utils.random_sample_from_masked_image_torch(mask, 5)\n",
    "    uv = uv.unsqueeze(0)\n",
    "    \n",
    "    # [B, 1, H, W]\n",
    "    depth_tensor = torch.Tensor(depth).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    z = pdc_utils.index_into_batch_image_tensor(depth_tensor, uv.transpose(1,2)).squeeze(1)\n",
    "    \n",
    "    # project to camera frame\n",
    "    pts = torch_utils.pinhole_unprojection(uv, z, K_inv)\n",
    "    \n",
    "    pts_np = pts.squeeze().cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    meshcat_utils.visualize_points(vis,\n",
    "                                   \"pts\",\n",
    "                                   pts_np,\n",
    "                                   color=[255,0,0],\n",
    "                                   size=0.02,\n",
    "                                   T=T_W_C)\n",
    "    \n",
    "    \n",
    "    rgb = np.copy(data_a['rgb'])\n",
    "    draw_reticles(rgb, uv[0,:,0], uv[0,:, 1], [255,0,0])\n",
    "    \n",
    "    sz = 2\n",
    "    figsize = (6.4*sz, 4.8*sz)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### TEST pinhole projection method\n",
    "    # [B, 3, 3]\n",
    "    K_torch = torch.from_numpy(K).unsqueeze(0)\n",
    "    \n",
    "    uv_proj = torch_utils.pinhole_projection(pts, K_torch)\n",
    "    \n",
    "    rgb_2 = np.copy(data_a['rgb'])\n",
    "    draw_reticles(rgb, uv_proj[0,:,0], uv_proj[0,:, 1], [0,255,0])\n",
    "    draw_reticles(rgb_2, uv_proj[0,:,0], uv_proj[0,:, 1], [0,255,0])\n",
    "    \n",
    "    sz = 2\n",
    "    figsize = (6.4*sz, 4.8*sz)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb_2)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    sz = 2\n",
    "    figsize = (6.4*sz, 4.8*sz)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cd = dataset._getitem(episode, None, camera_name_a, camera_name_b, idx_a=idx_a, idx_b=idx_b)\n",
    "\n",
    "pad_correspondence_data(cd, N_matches=10, N_masked_non_matches=20, N_background_non_matches=30, verbose=False)\n",
    "uv_a = cd['matches']['uv_a']\n",
    "uv_b = cd['matches']['uv_b']\n",
    "\n",
    "H = cd['data_a']['rgb_tensor'].shape[1]\n",
    "W = cd['data_a']['rgb_tensor'].shape[2]\n",
    "sigma_fraction = 0.003\n",
    "diag = np.sqrt(W**2 + H**2)\n",
    "sigma = sigma_fraction * diag\n",
    "\n",
    "print(\"H\", H)\n",
    "print(\"W\", W)\n",
    "# visualize some of them\n",
    "\n",
    "# create heatmap\n",
    "heatmap_tensor = loss_utils.create_heatmap(uv_b.permute([1,0]), H, W, sigma, type='exp')\n",
    "print(\"heatmap_tensor.shape\", heatmap_tensor.shape)\n",
    "\n",
    "\n",
    "idx_range = range(1)\n",
    "n = 0\n",
    "uv_a_short = uv_a[:, idx_range]\n",
    "uv_b_short = uv_b[:, idx_range]\n",
    "\n",
    "print(\"uv_a_short\", uv_a_short)\n",
    "print(\"uv_b_short\", uv_b_short)\n",
    "\n",
    "print(\"uv_a\", uv_a[:, :10])\n",
    "print(\"uv_b\", uv_b[:, :10])\n",
    "\n",
    "\n",
    "\n",
    "# plot matches\n",
    "# print(uv_a_short)\n",
    "images = [data_a['rgb'], data_b['rgb']]\n",
    "correspondence_plotter.plot_correspondences(images, uv_a_short, uv_b_short)\n",
    "\n",
    "# plot heatmap\n",
    "n = 0\n",
    "heatmap = heatmap_tensor[n, :, :].unsqueeze(-1).expand(*[-1,-1,3]).numpy()\n",
    "heatmap = heatmap_tensor[n, :, :].numpy()\n",
    "\n",
    "print(\"heatmap[v,u]\", heatmap[uv_b[1, n], uv_b[0, n]])\n",
    "\n",
    "heatmap_255 = np.uint8(255*heatmap)\n",
    "print(\"heatmap_255.dtype\", heatmap_255.dtype)\n",
    "\n",
    "print(\"heatmap_255[v,u]\", heatmap_255[uv_b[1, n], uv_b[0, n]])\n",
    "\n",
    "# this is in 'bgr', we want 'rgb'\n",
    "colormap = cv2.applyColorMap(heatmap_255, cv2.COLORMAP_JET)\n",
    "colormap_rgb = np.zeros_like(colormap)\n",
    "colormap_rgb[:,:,0] = colormap[:,:,2]\n",
    "colormap_rgb[:,:,2] = colormap[:,:,0]\n",
    "print(\"heatmap.max\", np.max(heatmap))\n",
    "print(\"heatmap min\", np.min(heatmap))\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(colormap_rgb)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "alpha = 0.3\n",
    "blend = alpha * colormap_rgb + (1-alpha) * data_b['rgb']\n",
    "blend = np.int16(blend)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(blend)\n",
    "plt.title('blend')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if False:\n",
    "\n",
    "    # plot non-matches\n",
    "    masked_non_matches_uv_a = cd['masked_non_matches']['uv_a'][:, idx_range]\n",
    "    masked_non_matches_uv_b = cd['masked_non_matches']['uv_b'][:, idx_range]\n",
    "    correspondence_plotter.plot_correspondences(images, masked_non_matches_uv_a, \n",
    "                                                masked_non_matches_uv_b, circ_color='r')\n",
    "    # plot non-matches\n",
    "    background_non_matches_uv_a = cd['background_non_matches']['uv_a'][:, idx_range]\n",
    "    background_non_matches_uv_b = cd['background_non_matches']['uv_b'][:, idx_range]\n",
    "    correspondence_plotter.plot_correspondences(images, background_non_matches_uv_a, \n",
    "                                                background_non_matches_uv_b, circ_color='r')\n",
    "\n",
    "\n",
    "    bnm_uv_a = cd['masked_non_matches']['uv_a']\n",
    "    print(\"bnm_uv_a.dtype\", bnm_uv_a.dtype)\n",
    "\n",
    "    bnm_uv_b = cd['masked_non_matches']['uv_b']\n",
    "    print(\"bnm_uv_b.dtype\", bnm_uv_b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Augmentation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_correspondence.dataset.image_augmentation import affine_augmentation, check_FOV\n",
    "pdc_utils.reset_random_seed(0)\n",
    "data = dataset._getitem(episode, None, camera_name_a, camera_name_b, idx_a=idx_a, idx_b=idx_b)\n",
    "print(data['data_a'].keys())\n",
    "print(data.keys())\n",
    "print(data['valid'])\n",
    "print(data['matches'].keys())\n",
    "\n",
    "\n",
    "# print(data['matches']['uv_a'][0])\n",
    "# print(data['masked_non_matches']['uv_b'][0])\n",
    "\n",
    "# print(data['matches']['uv_a'].shape)\n",
    "# print(data['masked_non_matches']['uv_a'].shape)\n",
    "\n",
    "# print(data['matches']['uv_b'][:, 0])\n",
    "# print(data['masked_non_matches']['uv_b'][:, 0])\n",
    "# print(data['background_non_matches']['uv_b'][:, 0])\n",
    "\n",
    "print(\"data['matches']['uv_a'].shape\", data['matches']['uv_a'].shape)\n",
    "\n",
    "image_name = 'data_a'\n",
    "uv_name = 'uv_a'\n",
    "\n",
    "image_name = 'data_b'\n",
    "uv_name = 'uv_b'\n",
    "\n",
    "images = [data[image_name]['rgb']]\n",
    "uv_pixel_positions = [data['matches'][uv_name], data['background_non_matches'][uv_name]]\n",
    "# uv_pixel_positions = [data['matches']['uv_a']]\n",
    "\n",
    "images_aug, uv_pixel_positions_aug = affine_augmentation(images, uv_pixel_positions, DEBUG=True)\n",
    "\n",
    "uv_pixel_aug_tmp = uv_pixel_positions_aug[1]\n",
    "valid = check_FOV(uv_pixel_aug_tmp, images_aug[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Augmentation through the Data Augmenter\n",
    "\n",
    "set the debug=True flag in affine_augmentation in image_augmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdc_utils.reset_random_seed(0)\n",
    "dataset._data_augmenter._enabled = True\n",
    "data = dataset._getitem(episode, None, camera_name_a, camera_name_b, idx_a=idx_a, idx_b=idx_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
