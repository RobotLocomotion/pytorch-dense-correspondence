{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this training notebook has itself been derived from the nice example at\n",
    "# https://github.com/warmspringwinds/pytorch-segmentation-detection/\n",
    "# under recipes/pascal_voc/segmentation/resnet_34_8s_train.ipynb\n",
    "\n",
    "# This script also uses the network model in\n",
    "# warmspringwinds/pytorch-segmentation-detection/\n",
    "\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.insert(0, '../pytorch-segmentation-detection/vision/')\n",
    "sys.path.append('../pytorch-segmentation-detection/')\n",
    "\n",
    "# Choose GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_segmentation_detection.models.fcn as fcns\n",
    "import pytorch_segmentation_detection.models.resnet_dilated as resnet_dilated\n",
    "from pytorch_segmentation_detection.transforms import (ComposeJoint,\n",
    "                                                       RandomHorizontalFlipJoint,\n",
    "                                                       RandomScaleJoint,\n",
    "                                                       CropOrPad,\n",
    "                                                       ResizeAspectRatioPreserve,\n",
    "                                                       RandomCropJoint,\n",
    "                                                       Split2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./dataset\")\n",
    "from labelfusion_masked import LabelFusionDataset\n",
    "trainset = LabelFusionDataset()\n",
    "\n",
    "# Note: in order to batch size larger than 1,\n",
    "# appears that the tensor sizes of matches and non_matches\n",
    "# will have to match across the batches\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=1, drop_last=True)\n",
    "\n",
    "\n",
    "# ### massively important parameter ###\n",
    "# set descriptor dimensionality here!!\n",
    "# should maybe move this somewhere that stands out more\n",
    "descriptor_dimensionality = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create the training plot\n",
    "loss_current_iteration = 0\n",
    "loss_history = []\n",
    "match_loss_history = []\n",
    "non_match_loss_history = []\n",
    "consistency_loss_history = []\n",
    "loss_iteration_number_history = []\n",
    "\n",
    "f, (loss_axis, match_loss_axis, non_match_loss_axis, consistency_loss_axis) = plt.subplots(4, 1)\n",
    "\n",
    "loss_axis.plot(loss_iteration_number_history, loss_history)\n",
    "loss_axis.set_title('Total loss')\n",
    "match_loss_axis.plot(loss_iteration_number_history, match_loss_history)\n",
    "match_loss_axis.set_title('Training loss -- matches only')\n",
    "non_match_loss_axis.plot(loss_iteration_number_history, non_match_loss_history)\n",
    "non_match_loss_axis.set_title('Training loss -- non matches only')\n",
    "consistency_loss_axis.plot(loss_iteration_number_history, consistency_loss_history)\n",
    "consistency_loss_axis.set_title('Training loss -- consistency only')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = resnet_dilated.Resnet34_8s(num_classes=descriptor_dimensionality)\n",
    "fcn.cuda()\n",
    "fcn.train()\n",
    "\n",
    "from pixelwise_contrastive_loss import PixelwiseContrastiveLoss\n",
    "pixelwise_contrastive_loss = PixelwiseContrastiveLoss()\n",
    "\n",
    "from semantic_consistency_loss import SemanticConsistencyLoss\n",
    "semantic_consistency_loss = SemanticConsistencyLoss()\n",
    "\n",
    "# note the lr specified here gets overwritten inside\n",
    "# adjust_learning_rate\n",
    "optimizer = optim.Adam(fcn.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "load_previous = None\n",
    "#load_previous = 'trained_models/debug_3d/dense_resnet_34_8s_04400.pth'\n",
    "if load_previous is not None:\n",
    "    print \"loading\", load_previous\n",
    "    fcn.load_state_dict(torch.load(load_previous))\n",
    "    optimizer.load_state_dict(torch.load(load_previous+\".optim\"))\n",
    "    fcn.cuda()\n",
    "    fcn.train()\n",
    "    loss_current_iteration = int(load_previous.split('.pth')[0][-5:])\n",
    "    print loss_current_iteration\n",
    "    \n",
    "\n",
    "def adjust_learning_rate(optimizer, iteration):\n",
    "    \"\"\"Pete: this also currently effectively stops training via an error\n",
    "    since at max_iterations+1, it tries to raise a negative number to a fractional power\"\"\"\n",
    "#     max_iteration = 10000.0\n",
    "#     multiplier = (1.0 - (iteration / max_iteration)) ** (0.9)\n",
    "#     lr = 0.00001 * multiplier\n",
    "    if loss_current_iteration % 500 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr']*0.9\n",
    "            \n",
    "def save_net(iteration):\n",
    "    folder_to_save = os.path.join(os.getcwd(),'trained_models/5drillscenes_maskedmatches_'+str(descriptor_dimensionality)+'d/')\n",
    "    os.system(\"mkdir -p \"+folder_to_save)\n",
    "    net_to_save = 'dense_resnet_34_8s_'+str(iteration).zfill(5)+'.pth'\n",
    "    net_to_save = os.path.join(folder_to_save, net_to_save)\n",
    "    print \"saving\", net_to_save\n",
    "    torch.save(fcn.state_dict(), net_to_save)\n",
    "    torch.save(optimizer.state_dict(), net_to_save+\".optim\")\n",
    "\n",
    "if loss_current_iteration == 0:\n",
    "    save_net(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "loss = match_loss = non_match_loss = consistency_loss = 0\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        loss_current_iteration += 1\n",
    "        start_iter = time.time()\n",
    "\n",
    "        # get the inputs\n",
    "        data_type, img_a, img_b, matches_a, matches_b, non_matches_a, non_matches_b = data\n",
    "        data_type = data_type[0]\n",
    "        \n",
    "        if len(matches_a[0]) == 0:\n",
    "            print \"didn't have any matches, continuing\"\n",
    "            continue\n",
    "            \n",
    "        img_a = Variable(img_a.cuda(), requires_grad=False)\n",
    "        img_b = Variable(img_b.cuda(), requires_grad=False)\n",
    "        \n",
    "        W = 640\n",
    "        H = 480\n",
    "        N = 1\n",
    "        \n",
    "        if data_type == \"matches\":\n",
    "            matches_a = Variable(matches_a.cuda().squeeze(0), requires_grad=False)\n",
    "            matches_b = Variable(matches_b.cuda().squeeze(0), requires_grad=False)\n",
    "            non_matches_a = Variable(non_matches_a.cuda().squeeze(0), requires_grad=False)\n",
    "            non_matches_b = Variable(non_matches_b.cuda().squeeze(0), requires_grad=False)\n",
    "            \n",
    "        elif data_type == \"masks\":\n",
    "            mask_a = Variable(matches_a.cuda().squeeze(0), requires_grad=False)\n",
    "            mask_a = mask_a/torch.max(mask_a)\n",
    "            mask_b = Variable(matches_b.cuda().squeeze(0), requires_grad=False)\n",
    "            mask_b = mask_b/torch.max(mask_b)\n",
    "            mask_a = mask_a.view(W*H,1).squeeze(1)\n",
    "            mask_b = mask_b.view(W*H,1).squeeze(1)\n",
    "            print mask_a.shape\n",
    "            print torch.max(mask_a)\n",
    "            print mask_b.shape\n",
    "            print torch.max(mask_b)\n",
    "        \n",
    "            \n",
    "        #print time.time() - start_iter, \"loading inputs\"\n",
    "        #start = time.time()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        adjust_learning_rate(optimizer, loss_current_iteration)\n",
    "        \n",
    "        #print time.time() - start, \"putting on GPU and adjusting optimizer\"\n",
    "        #start = time.time()\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        def process_net_output(image_pred):\n",
    "            image_pred = image_pred.view(N,descriptor_dimensionality,W*H)\n",
    "            image_pred = image_pred.permute(0, 2, 1)\n",
    "            return image_pred\n",
    "\n",
    "\n",
    "        image_a_pred = fcn(img_a)\n",
    "        image_a_pred = process_net_output(image_a_pred)\n",
    "\n",
    "        image_b_pred = fcn(img_b)\n",
    "        image_b_pred = process_net_output(image_b_pred)\n",
    "        \n",
    "        #print time.time() - start, \"forwarding\"\n",
    "        start = time.time()\n",
    "        #print matches_a.shape\n",
    "\n",
    "        # get loss\n",
    "        if data_type == \"matches\":\n",
    "            loss, match_loss, non_match_loss = pixelwise_contrastive_loss.get_loss(image_a_pred, image_b_pred, matches_a, \n",
    "                                            matches_b, non_matches_a, non_matches_b)\n",
    "        elif data_type == \"masks\":\n",
    "            loss = semantic_consistency_loss.get_loss(image_a_pred, image_b_pred,\n",
    "                                                      mask_a, mask_b) \n",
    "            consistency_loss = loss\n",
    "        \n",
    "        #print time.time() - start, \"getting loss\"\n",
    "        start = time.time()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print time.time() - start, \"backprop\"\n",
    "        start = time.time()\n",
    "\n",
    "        loss_history.append(loss.data[0])\n",
    "        match_loss_history.append(match_loss)\n",
    "        non_match_loss_history.append(non_match_loss)\n",
    "        loss_iteration_number_history.append(loss_current_iteration)\n",
    "        consistency_loss_history.append(consistency_loss)\n",
    "        \n",
    "        if loss_current_iteration % 10 == 0:\n",
    "            loss_axis.lines[0].set_xdata(loss_iteration_number_history)\n",
    "            loss_axis.lines[0].set_ydata(loss_history)\n",
    "            loss_axis.relim()\n",
    "            loss_axis.autoscale_view()\n",
    "            loss_axis.figure.canvas.draw()\n",
    "            match_loss_axis.lines[0].set_xdata(loss_iteration_number_history)\n",
    "            match_loss_axis.lines[0].set_ydata(match_loss_history)\n",
    "            match_loss_axis.relim()\n",
    "            match_loss_axis.autoscale_view()\n",
    "            match_loss_axis.figure.canvas.draw()\n",
    "            non_match_loss_axis.lines[0].set_xdata(loss_iteration_number_history)\n",
    "            non_match_loss_axis.lines[0].set_ydata(non_match_loss_history)\n",
    "            non_match_loss_axis.relim()\n",
    "            non_match_loss_axis.autoscale_view()\n",
    "            non_match_loss_axis.figure.canvas.draw()\n",
    "            consistency_loss_axis.lines[0].set_xdata(loss_iteration_number_history)\n",
    "            consistency_loss_axis.lines[0].set_ydata(consistency_loss_history)\n",
    "            consistency_loss_axis.relim()\n",
    "            consistency_loss_axis.autoscale_view()\n",
    "            consistency_loss_axis.figure.canvas.draw()\n",
    "        \n",
    "        #print time.time() - start, \"plotting\"\n",
    "        start = time.time()\n",
    "\n",
    "        print time.time() - start_iter, \"total seconds on gpu \" + os.environ[\"CUDA_VISIBLE_DEVICES\"]\n",
    "        print (i, loss.data[0])\n",
    "        if loss_current_iteration % 500 == 0:\n",
    "            save_net(loss_current_iteration)\n",
    "\n",
    "            #reset plots so they autozoom better\n",
    "            loss_iteration_number_history = []\n",
    "            loss_history = []\n",
    "            match_loss_history = []\n",
    "            non_match_loss_history = []\n",
    "            consistency_loss_history = []\n",
    "            \n",
    "        if loss_current_iteration > 3500:\n",
    "            raise ValueError(\"done\")\n",
    "\n",
    "print \"Done!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
