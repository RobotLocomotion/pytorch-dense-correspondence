{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# pdc\n",
    "from dense_correspondence_manipulation.utils.utils import set_cuda_visible_devices\n",
    "\n",
    "GPU_LIST = [1]\n",
    "set_cuda_visible_devices(GPU_LIST)\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# pdc\n",
    "from dense_correspondence.dataset.dynamic_drake_sim_dataset import DynamicDrakeSimDataset\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import reproject_pixels\n",
    "from dense_correspondence.correspondence_tools import correspondence_plotter\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import compute_correspondence_data, pad_correspondence_data\n",
    "from dense_correspondence_manipulation.utils.utils import getDenseCorrespondenceSourceDir\n",
    "import dense_correspondence.loss_functions.utils as loss_utils\n",
    "import dense_correspondence_manipulation.utils.utils as pdc_utils\n",
    "from dense_correspondence.network import predict\n",
    "\n",
    "# pdc\n",
    "from dense_correspondence.dataset.dynamic_drake_sim_dataset import DynamicDrakeSimDataset\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import reproject_pixels\n",
    "from dense_correspondence.correspondence_tools import correspondence_plotter\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import compute_correspondence_data, pad_correspondence_data\n",
    "from dense_correspondence_manipulation.utils.utils import getDenseCorrespondenceSourceDir, getDictFromYamlFilename\n",
    "import dense_correspondence_manipulation.utils.utils as pdc_utils\n",
    "import dense_correspondence.loss_functions.utils as loss_utils\n",
    "from dense_correspondence.dataset.spartan_episode_reader import SpartanEpisodeReader\n",
    "import dense_correspondence_manipulation.utils.visualization as vis_utils\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n')\n",
    "print(\"device_count\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = os.getenv(\"DATA_ROOT\")\n",
    "episodes_root = os.path.join(os.getenv(\"DATA_ROOT\"), \"pdc/logs_proto\")\n",
    "print(\"episodes_root\", episodes_root)\n",
    "episode_list_config = getDictFromYamlFilename(os.path.join(getDenseCorrespondenceSourceDir(), \n",
    "                                                          'config/dense_correspondence/dataset/single_object/caterpillar_9_episodes.yaml'))\n",
    "multi_episode_dict = SpartanEpisodeReader.load_dataset(episode_list_config,\n",
    "                                                      episodes_root)\n",
    "\n",
    "config_file = os.path.join(getDenseCorrespondenceSourceDir(), 'config/dense_correspondence/global/drake_sim_dynamic.yaml')\n",
    "config = getDictFromYamlFilename(config_file)\n",
    "dataset = DynamicDrakeSimDataset(config, multi_episode_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join(DATA_ROOT,\n",
    "                          \"pdc/dev/experiments/heatmap/trained_models/2020-02-06-20-42-49_resnet50__dataset_caterpillar_9/net_dy_epoch_0_iter_10000_model.pth\")\n",
    "\n",
    "\n",
    "model_file = os.path.join(DATA_ROOT, \"pdc/dev/experiments/heatmap/trained_models/2020-02-13-21-38-56_resnet50__dataset_caterpillar_9_spatial_expectation_enabled/net_dy_epoch_0_iter_3000_model.pth\")\n",
    "model_config = getDictFromYamlFilename(os.path.join(os.path.dirname(model_file), 'config.yaml'))\n",
    "model = torch.load(model_file)\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Load a pair images, visualize ground truth an estimated correspondences\n",
    "\n",
    "sz = 3\n",
    "figsize = (6.4*sz, 4.8*sz)\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "K = 4 # num matches to display\n",
    "\n",
    "\n",
    "episode_name = list(multi_episode_dict.keys())[0]\n",
    "episode = dataset.episodes[episode_name]\n",
    "camera_names = list(episode.camera_names)\n",
    "camera_name_a = camera_names[0]\n",
    "camera_name_b = camera_names[0]\n",
    "\n",
    "idx_list = [10,30,60,100]\n",
    "\n",
    "for j in idx_list:\n",
    "\n",
    "    idx=0\n",
    "    idx_a = 0\n",
    "    idx_b = episode.indices[j]\n",
    "    data = dataset._getitem(episode, idx, camera_name_a, camera_name_b, idx_a=idx_a, idx_b=idx_b)\n",
    "\n",
    "\n",
    "    ## Visualize both rgb images with a few ground truth correspondences in green\n",
    "    ## Learned correspondences will be in red . . . \n",
    "\n",
    "    # figname = \"target idx: %d\" %(idx)\n",
    "    # fig = plt.figure(figname, figsize=figsize)\n",
    "    # axes = fig.subplots(num_rows, num_cols, squeeze=False)\n",
    "    uv_a = data['matches']['uv_a'][:,:K] # [2, num_matches]\n",
    "    uv_b = data['matches']['uv_b'][:,:K] # [2, num_matches]\n",
    "    rgb_a = np.copy(data['data_a']['rgb'])\n",
    "    rgb_b = np.copy(data['data_b']['rgb'])\n",
    "\n",
    "    # compute sigma\n",
    "    H = data['data_a']['rgb_tensor'].shape[1]\n",
    "    W = data['data_a']['rgb_tensor'].shape[2]\n",
    "    sigma_fraction = config['loss_function']['heatmap']['sigma_fraction']\n",
    "    diag = np.sqrt(W**2 + H**2)\n",
    "    sigma = sigma_fraction * diag\n",
    "\n",
    "\n",
    "    # draw reticles on image a\n",
    "    label_color = [0, 255, 0]\n",
    "    vis_utils.draw_reticles(rgb_a,\n",
    "                            uv_a[0, :],\n",
    "                            uv_a[1, :],\n",
    "                            label_color)\n",
    "\n",
    "    # ax = axes[0,0]\n",
    "    # ax.imshow(rgb_a)\n",
    "\n",
    "    label_color = [0, 255, 0]\n",
    "    vis_utils.draw_reticles(rgb_b,\n",
    "                            uv_b[0, :],\n",
    "                            uv_b[1, :],\n",
    "                            label_color)\n",
    "    # ax = axes[0,1]\n",
    "    # ax.imshow(rgb_b)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # now localize the correspondences\n",
    "        # push rgb_a, rgb_b through the network\n",
    "        rgb_tensor_a = data['data_a']['rgb_tensor'].unsqueeze(0).cuda()\n",
    "        out_a = model.forward(rgb_tensor_a)\n",
    "        des_img_a = out_a['descriptor_image']\n",
    "\n",
    "        rgb_tensor_b = data['data_b']['rgb_tensor'].unsqueeze(0).cuda()\n",
    "        out_b = model.forward(rgb_tensor_b)\n",
    "        des_img_b = out_b['descriptor_image']\n",
    "\n",
    "        # extract descriptors corresponding to uv_a in des_a\n",
    "        # [B, K, D]\n",
    "        des_a = pdc_utils.index_into_batch_image_tensor(des_img_a, uv_a.unsqueeze(0).cuda()).permute([0,2,1])\n",
    "\n",
    "        # localize these in the other image\n",
    "        # find best match in des_img_b\n",
    "        \n",
    "        # argmax\n",
    "        best_match_dict = predict.get_argmax_l2(des_a, des_img_b)\n",
    "\n",
    "        # [2, K]\n",
    "        best_match_uv_b = best_match_dict['indices'].permute([0, 2, 1]).squeeze()\n",
    "        \n",
    "        # spatial expectation\n",
    "        spatial_pred = predict.get_spatial_expectation(des_a, \n",
    "                                        des_img_b, \n",
    "                                        sigma=config['network']['sigma_descriptor_heatmap'],\n",
    "                                        type='exp', return_heatmap=True)\n",
    "        \n",
    "        # [K, 2]\n",
    "        uv_spatial_pred = spatial_pred['uv'].squeeze()\n",
    "        print(\"uv_spatial_pred.shape\", uv_spatial_pred.shape)\n",
    "        \n",
    "\n",
    "        print(\"des_a.shape\", des_a.shape)\n",
    "        print(\"best_match_uv_b.shape\", best_match_uv_b.shape)\n",
    "\n",
    "\n",
    "#     label_color = [255, 0, 0] # red\n",
    "#     vis_utils.draw_reticles(rgb_b,\n",
    "#                             best_match_uv_b[0, :],\n",
    "#                             best_match_uv_b[1, :],\n",
    "#                             label_color)\n",
    "    \n",
    "    label_color = [0, 0, 255] # blue\n",
    "    label_color = [255, 0, 0]\n",
    "    vis_utils.draw_reticles(rgb_b,\n",
    "                            uv_spatial_pred[:, 0],\n",
    "                            uv_spatial_pred[:, 1],\n",
    "                            label_color)\n",
    "\n",
    "\n",
    "    figname = \"learned correspondences %d\" %(j)\n",
    "    fig = plt.figure(figname, figsize=figsize)\n",
    "    axes = fig.subplots(num_rows, num_cols, squeeze=False)\n",
    "    ax = axes[0,0]\n",
    "    ax.imshow(rgb_a)\n",
    "\n",
    "    ax = axes[0,1]\n",
    "    ax.imshow(rgb_b)\n",
    "\n",
    "    # compute heatmaps\n",
    "    # this is the heatmap that an individual descriptor from rgb_a\n",
    "    # will induce given descriptor image b (des_img_b)\n",
    "    # [B,N,H,W]\n",
    "#     heatmap_pred = loss_utils.compute_heatmap_from_descriptors(des_a,\n",
    "#                                                                des_img_b,\n",
    "#                                                                sigma=sigma,\n",
    "#                                                                type=config['loss_function']['heatmap']['heatmap_type'])\n",
    "    \n",
    "    heatmap_pred = spatial_pred['heatmap']\n",
    "\n",
    "\n",
    "    # visualize heatmaps\n",
    "    for k in range(K):\n",
    "        heatmap = heatmap_pred[0, k].detach().cpu().numpy() # [H, W]\n",
    "        heatmap_rgb = vis_utils.colormap_from_heatmap(heatmap)\n",
    "        figname = \"heatmap %d\" %(k)\n",
    "        fig = plt.figure(figname, figsize=(6.4, 4.8))\n",
    "        axes = fig.subplots(1, 1, squeeze=False)\n",
    "        ax = axes[0,0]\n",
    "        ax.imshow(heatmap_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
