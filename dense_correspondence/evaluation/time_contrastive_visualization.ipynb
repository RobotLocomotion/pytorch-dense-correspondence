{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "\n",
    "import dense_correspondence\n",
    "from dense_correspondence.evaluation.evaluation import *\n",
    "import dense_correspondence.correspondence_tools.correspondence_plotter as correspondence_plotter\n",
    "from dense_correspondence.dataset.dense_correspondence_dataset_masked import ImageType\n",
    "from dense_correspondence.dataset.dynamic_time_contrast_dataset import DynamicTimeContrastDataset\n",
    "\n",
    "# LOAD DATASET\n",
    "dataset_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', 'dense_correspondence',\n",
    "                                       'dataset', 'composite',\n",
    "                                       'dynamic.yaml')\n",
    "dataset_config = utils.getDictFromYamlFilename(dataset_config_filename)\n",
    "dataset = DynamicTimeContrastDataset(config=dataset_config)\n",
    "\n",
    "# LOAD DESCRIPTOR NETWORK\n",
    "eval_config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config', \n",
    "                               'dense_correspondence', 'evaluation', 'evaluation.yaml')\n",
    "eval_config = utils.getDictFromYamlFilename(eval_config_filename)\n",
    "\n",
    "utils.set_cuda_visible_devices([0])\n",
    "dce = DenseCorrespondenceEvaluation(eval_config)\n",
    "network_name = \"sugar_closer_3\"\n",
    "dcn = dce.load_network_from_config(network_name)\n",
    "dcn.cuda().eval()\n",
    "print \"loaded dcn\"\n",
    "\n",
    "# load tcn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeEmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, D):\n",
    "        super(TimeEmbeddingNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(6, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 3, 5)\n",
    "        self.fc1 = nn.Linear(12768, 12768)\n",
    "        self.fc2 = nn.Linear(12768, 12768)\n",
    "        self.fc3 = nn.Linear(12768, D)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1,12768)\n",
    "        drop = nn.Dropout(0.1)\n",
    "        x = F.relu(drop(self.fc1(x)))\n",
    "        x = F.relu(drop(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "D_embedding = 32\n",
    "model = TimeEmbeddingNetwork(D=D_embedding).cuda()\n",
    "model.load_state_dict(torch.load(\"/home/peteflo/code/dense_correspondence/training/tensorboard_log_dir/2019-02-23-19-41-36/norm_net.pth\"))\n",
    "model.eval()\n",
    "print \"loaded tcn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get camera_0 rgb image for each index of a certain log\n",
    "log_a = \"2019-02-22-18-41-39\" # REFERENCE TRAJECTORY\n",
    "#log_a = \"2019-02-22-19-44-16\"\n",
    "\n",
    "# get nu\n",
    "scene_directory = dataset.get_full_path_for_scene(log_a)\n",
    "state_info_filename = os.path.join(scene_directory, \"states.yaml\")\n",
    "state_info_dict = utils.getDictFromYamlFilename(state_info_filename)\n",
    "image_idxs = state_info_dict.keys() # list of integers\n",
    "\n",
    "camera_num = 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embeddings = np.zeros((len(image_idxs),D_embedding))\n",
    "colors = np.zeros((len(image_idxs)))\n",
    "print embeddings.shape\n",
    "print colors.shape\n",
    "\n",
    "for i in image_idxs:\n",
    "    rgb = dataset.get_rgb_image(dataset.get_image_filename(log_a, camera_num, i, ImageType.RGB))\n",
    "    rgb_tensor = dataset.rgb_image_to_tensor(rgb)\n",
    "    rgb_tensor = rgb_tensor.unsqueeze(0).cuda() #N, C, H, W\n",
    "    descriptor_image = dcn.forward(rgb_tensor).detach() #N, D, H, W\n",
    "    stacked = torch.cat([rgb_tensor[0], descriptor_image[0]]).unsqueeze(0)\n",
    "    embedding = model(stacked)[0].detach().cpu().numpy()\n",
    "    embeddings[i] = embedding\n",
    "    colors[i] = float(i) / float(len(image_idxs))\n",
    "    \n",
    "last_index = i*1\n",
    "\n",
    "# #camera_num = 1\n",
    "log_b = \"2019-02-22-18-42-22\" # LOOKUP TRAJECTORY\n",
    "#log_b = \"2019-02-22-18-42-03\"\n",
    "#log_b = \"2019-02-22-18-25-16\"\n",
    "#log_b = \"2019-02-22-18-25-16\"\n",
    "\n",
    "scene_directory = dataset.get_full_path_for_scene(log_b)\n",
    "state_info_filename = os.path.join(scene_directory, \"states.yaml\")\n",
    "state_info_dict = utils.getDictFromYamlFilename(state_info_filename)\n",
    "image_idxs = state_info_dict.keys() # list of integers\n",
    "\n",
    "embeddings_new = np.zeros((len(image_idxs),D_embedding))\n",
    "colors_new = np.zeros((len(image_idxs)))\n",
    "embeddings = np.vstack((embeddings, embeddings_new))\n",
    "colors = np.hstack((colors, colors_new))\n",
    "\n",
    "for i in image_idxs:\n",
    "    last_index += 1\n",
    "    rgb = dataset.get_rgb_image(dataset.get_image_filename(log_b, camera_num, i, ImageType.RGB))\n",
    "    rgb_tensor = dataset.rgb_image_to_tensor(rgb)\n",
    "    rgb_tensor = rgb_tensor.unsqueeze(0).cuda() #N, C, H, W\n",
    "    descriptor_image = dcn.forward(rgb_tensor).detach() #N, D, H, W\n",
    "    stacked = torch.cat([rgb_tensor[0], descriptor_image[0]]).unsqueeze(0)\n",
    "    embedding = model(stacked)[0].detach().cpu().numpy()\n",
    "    embeddings[last_index] = embedding\n",
    "    colors[last_index] = float(i) / float(len(image_idxs))\n",
    "    \n",
    "print embeddings.shape\n",
    "print colors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jake Vanderplas -- <vanderplas@astro.washington.edu>\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "# Next line to silence pyflakes. This import is needed.\n",
    "Axes3D\n",
    "\n",
    "X, color = embeddings, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 10\n",
    "n_components = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "plt.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n",
    "             % (1000, n_neighbors), fontsize=14)\n",
    "\n",
    "# ax = fig.add_subplot(251, projection='3d')\n",
    "# ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "# ax.view_init(4, -72)\n",
    "\n",
    "methods = ['standard', 'ltsa', 'hessian', 'modified']\n",
    "labels = ['LLE', 'LTSA', 'Hessian LLE', 'Modified LLE']\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    t0 = time()\n",
    "    Y = manifold.LocallyLinearEmbedding(n_neighbors, n_components,\n",
    "                                        eigen_solver='auto',\n",
    "                                        method=method).fit_transform(X)\n",
    "    t1 = time()\n",
    "    print(\"%s%\", methods[i])\n",
    "\n",
    "    ax = fig.add_subplot(252 + i)\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "    plt.title(\"%s\" % labels[i])\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    plt.axis('tight')\n",
    "\n",
    "t0 = time()\n",
    "Y = manifold.Isomap(n_neighbors, n_components).fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"Isomap\")\n",
    "ax = fig.add_subplot(257)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"Isomap\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "mds = manifold.MDS(n_components, max_iter=100, n_init=1)\n",
    "Y = mds.fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"MDS\")\n",
    "ax = fig.add_subplot(258)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"MDS\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "se = manifold.SpectralEmbedding(n_components=n_components,\n",
    "                                n_neighbors=n_neighbors)\n",
    "Y = se.fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"SpectralEmbedding\")\n",
    "ax = fig.add_subplot(259)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"SpectralEmbedding\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "t0 = time()\n",
    "tsne = manifold.TSNE(n_components=n_components, init='pca', random_state=0)\n",
    "Y = tsne.fit_transform(X)\n",
    "t1 = time()\n",
    "print(\"t-SNE: %.2g sec\" % (t1 - t0))\n",
    "ax = fig.add_subplot(2, 5, 10)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)\n",
    "plt.title(\"t-SNE\")\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make videos\n",
    "from dense_correspondence.evaluation.plotting import normalize_descriptor\n",
    "\n",
    "print log_a\n",
    "scene_directory = dataset.get_full_path_for_scene(log_a)\n",
    "state_info_filename = os.path.join(scene_directory, \"states.yaml\")\n",
    "state_info_dict = utils.getDictFromYamlFilename(state_info_filename)\n",
    "image_idxs = state_info_dict.keys() # list of integers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "\n",
    "for i in image_idxs:\n",
    "    rgb = dataset.get_rgb_image(dataset.get_image_filename(log_a, camera_num, i, ImageType.RGB))\n",
    "    rgb_tensor = dataset.rgb_image_to_tensor(rgb)\n",
    "    rgb_tensor = rgb_tensor.unsqueeze(0).cuda() #N, C, H, W\n",
    "    descriptor_image = dcn.forward(rgb_tensor).detach() #N, D, H, W\n",
    "    \n",
    "    mask = dataset.get_mask_image(dataset.get_image_filename(log_a, camera_num, i, ImageType.MASK))\n",
    "    mask_three_channel = np.ones((480,640,3))\n",
    "    for j in range(3):\n",
    "        mask_three_channel[:,:,j] = np.asarray(mask)\n",
    "    rgb_numpy = np.asarray(rgb)/255.0\n",
    "    \n",
    "    descriptor_numpy = descriptor_image[0].permute(1,2,0).cpu().numpy()\n",
    "    descriptor_numpy = normalize_descriptor(descriptor_numpy, dcn.descriptor_image_stats[\"mask_image\"])\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3)\n",
    "    fig.set_figheight(20*480/640)\n",
    "    fig.set_figwidth(30)\n",
    "    axes[0,0].imshow(rgb_numpy)\n",
    "    axes[0,1].imshow(descriptor_numpy)\n",
    "    axes[0,2].imshow(descriptor_numpy*mask_three_channel)\n",
    "    \n",
    "    # LOOK UP CLOSEST IN OTHER LOG\n",
    "    embedding_a = embeddings[i]\n",
    "    \n",
    "    closest_dist = 1e9\n",
    "    closest_embedding_idx = None\n",
    "    for j, embedding_b in enumerate(embeddings[len(image_idxs):]):\n",
    "        dist = LA.norm(embedding_b - embedding_a)\n",
    "        if dist < closest_dist:\n",
    "            closest_dist = dist\n",
    "            closest_embedding_idx = j\n",
    "    \n",
    "    embeddings_b = embeddings[len(image_idxs):]\n",
    "    rgb = dataset.get_rgb_image(dataset.get_image_filename(log_b, camera_num, closest_embedding_idx, ImageType.RGB))\n",
    "    rgb_tensor = dataset.rgb_image_to_tensor(rgb)\n",
    "    rgb_tensor = rgb_tensor.unsqueeze(0).cuda() #N, C, H, W\n",
    "    descriptor_image = dcn.forward(rgb_tensor).detach() #N, D, H, W\n",
    "    \n",
    "    mask = dataset.get_mask_image(dataset.get_image_filename(log_b, camera_num, closest_embedding_idx, ImageType.MASK))\n",
    "    mask_three_channel = np.ones((480,640,3))\n",
    "    for j in range(3):\n",
    "        mask_three_channel[:,:,j] = np.asarray(mask)\n",
    "    rgb_numpy = np.asarray(rgb)/255.0\n",
    "    \n",
    "    descriptor_numpy = descriptor_image[0].permute(1,2,0).cpu().numpy()\n",
    "    descriptor_numpy = normalize_descriptor(descriptor_numpy, dcn.descriptor_image_stats[\"mask_image\"])\n",
    "    axes[1,0].imshow(rgb_numpy)\n",
    "    axes[1,1].imshow(descriptor_numpy)\n",
    "    axes[1,2].imshow(descriptor_numpy*mask_three_channel)\n",
    "    axes[0,0].set_ylabel('reference', fontsize=25)\n",
    "    axes[1,0].set_ylabel('nearest neighbor', fontsize=25)\n",
    "    os.system(\"mkdir -p ./lookup_vis/\")\n",
    "    fig.savefig(\"./lookup_vis/new_\"+str(i).zfill(5)+\".png\", dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VIDEO\n",
    "import os\n",
    "\n",
    "chdir = os.path.join(os.getcwd(),\"lookup_vis\")\n",
    "os.system(\"cd \"+chdir)\n",
    "cmd = \"cd \"+chdir+\" && ffmpeg -f image2 -framerate 30 -pattern_type glob -i '*.png' -pix_fmt yuv420p out.mp4\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
